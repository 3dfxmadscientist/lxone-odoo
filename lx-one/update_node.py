from openerp.osv import osv, fields
from openerp.tools.translate import _

import json

from lx_data import lx_data
from lx_purchase_order import lx_purchase_order
from lx_sales_order import lx_sales_order
from lx_product import lx_product
from lx_return import lx_return
from lx_stock import lx_stock
from lx_picking import lx_picking
from lx_test import lx_test

class lx_update_node(osv.osv):
    """
    These records represent data coming from LX1. Each one should be able to be executed
    independently from the rest, i.e. the reception of a picking order or a physical inventory.

    They are designed to be generated by the parsed xml in an lx.update.file, that is downloaded from 
    LX1's FTP server, and executed in the same order that they were created.
    """

    _name = 'lx.update.node'
    
    def _get_name(self, cr, uid, ids, field_name, arg, context):
        res = dict.fromkeys(ids)
        for node in self.browse(cr, uid, ids, context=context):
            res[node.id] = '%s, Node %s' % (node.update_file_id.file_name, node.node_number)
        return res

    _columns = {
        'name': fields.function(_get_name, type='char', method=True, string="Name"),
        'create_date' : fields.datetime('Create Date', readonly=True),
        'update_file_id': fields.many2one('lx.update.file', 'File'),
        'sequence': fields.char('Execution Sequence', required=True, readonly=True),
        'state': fields.selection( (
                ('to_execute', 'To Execute'), 
                ('executed', 'Executed'), 
                ('failed', 'Failed')
            ), 'State'),
        'object_type': fields.char('Object Type', size=12, required=True, readonly=True),
        'data': fields.text('Data', required=True,),
        'result': fields.text('Execution Result', readonly=True),
        'node_number': fields.integer('XML Node Number', required=True, readonly=True),
    }

    _defaults = { 
        'state': 'to_execute',
        'sequence': lambda obj, cr, uid, context: obj.pool.get('ir.sequence').get(cr, uid, 'lx.update.node')
    }
    
    def _sanitize_values(self, vals):
        """ Pretty print data field contents """
        if vals.get('data'):
            vals['data'] = json.dumps(vals['data'], indent=4, ensure_ascii=False)
            
        if 'state' in vals and 'result' not in vals:
            vals['result'] = ''
            
        return vals
    
    def create(self, cr, uid, vals, context=None):
        """ Sanitize values """
        vals = self._sanitize_values(vals)
        return super(lx_update_node, self).create(cr, uid, vals, context=context)
    
    def write(self, cr, uid, ids, vals, context=None):
        """ sanitize values """
        vals = self._sanitize_values(vals)
        return super(lx_update_node, self).write(cr, uid, ids, vals, context=context)

    def execute(self, cr, uid, ids, context=None):
        """
        Sorts IDs by their sequence, then find an appropriate lx_data child class based on 
        the node.object_type and lx_data.file_name_prefix, instantiate it and call process.
        Then set state to executed, or catch errors and set as failed.
        """
        nodes = self.read(cr, uid, ids, ['sequence'], context=context)
        nodes.sort(key=lambda node: int(node['sequence']))
        for node in nodes:
            node = self.browse(cr, uid, node['id'], context=context)
            
            if node.state == 'executed':
                continue
            
            # do execution
            try:
                # find appropriate lx_data class, instantiate it, and trigger process
                class_for_data_type = [cls for cls in lx_data.__subclasses__() if node.object_type in cls.file_name_prefix]
                assert len(class_for_data_type) == 1, _('Should have found 1 class for data type %s' % node.object_type)
                data = class_for_data_type[0](json.loads(node.data))
                data.process(self.pool, cr)
            
                # change state
                node.write({'state': 'executed'})
                
                # trigger update.file state check
                node.update_file_id.check_still_waiting()
                
            except Exception, e:
                result = 'Error while executing: %s' % unicode(e)
                node.write({'state': 'failed', 'result': result})

    def execute_all(self, cr, uid, ids=[], context=None):
        """ Gets ids for all nodes whose state is not executed and calls execute on them """
        all_ids = self.search(cr, uid, [('state', '!=', 'executed')], context=context)
        self.execute(cr, uid, all_ids)
